
// scraper.js
const axios = require('axios');
const cheerio = require('cheerio');

async function scrapeWebsite(url, selectors) {
  try {
    const response = await axios.get(url);
    const html = response.data;
    const $ = cheerio.load(html);
    const articles = [];

    $(selectors.article).each((i, el) => {
      const titleElement = $(el).find(selectors.title);
      const linkElement = $(el).find(selectors.link);
      const dateElement = $(el).find(selectors.date);
      const excerptElement = $(el).find(selectors.excerpt);

      const title = titleElement ? titleElement.text().trim() : '';
      const link = linkElement ? linkElement.attr('href') : '';
      const date = dateElement ? dateElement.text().trim() : '';
      const excerpt = excerptElement ? excerptElement.text().trim() : '';

      if (title && link) {
        articles.push({ title, link, date, excerpt, source: new URL(url).hostname });
      }
    });

    return articles;
  } catch (error) {
    console.error(`Error al hacer scraping en ${url}: ${error}`);
    return [];
  }
}

module.exports = { scrapeWebsite };
const ejemploSelector = {
    article: '.noticia-principal o .noticia-secundaria', // Selector para cada bloque de noticia
    title: '.titulo-noticia a',
    link: '.titulo-noticia a',
    date: '.fecha-publicacion',
    excerpt: '.resumen-noticia'
  };
  